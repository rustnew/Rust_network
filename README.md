
# ğŸ§  Neural Network from Scratch in Rust

Un **rÃ©seau de neurones entiÃ¨rement codÃ© Ã  la main en Rust ğŸ¦€**, sans framework dâ€™apprentissage automatique externe.
Ce projet implÃ©mente toutes les Ã©tapes de base du machine learning : **initialisation, propagation avant, rÃ©tropropagation, mise Ã  jour des poids et Ã©valuation**.

---

## âœ¨ Sommaire

1. [Introduction](#-introduction)
2. [Architecture du rÃ©seau](#-architecture-du-rÃ©seau)
3. [Principe de fonctionnement](#-principe-de-fonctionnement)
4. [Formules mathÃ©matiques](#-formules-mathÃ©matiques)
5. [Structure du code](#-structure-du-code)
6. [Exemple dâ€™utilisation](#-exemple-dutilisation)
7. [RÃ©sultats attendus](#-rÃ©sultats-attendus)
8. [AmÃ©liorations possibles](#-amÃ©liorations-possibles)

---

## ğŸš€ Introduction

Ce projet montre comment **implÃ©menter un rÃ©seau de neurones (Neural Network)** *from scratch* en **Rust**, en manipulant directement les **poids, biais, activations et gradients**.

Aucun framework comme TensorFlow ou PyTorch nâ€™est utilisÃ© â€” tout est fait Ã  la main pour une comprÃ©hension profonde du **fonctionnement interne dâ€™un rÃ©seau de neurones**.

---

## ğŸ§© Architecture du rÃ©seau

Le rÃ©seau est composÃ© dâ€™une sÃ©rie de **couches (`Layer`)** reliÃ©es sÃ©quentiellement :

```
Input Layer  â†’  Hidden Layers  â†’  Output Layer
```

Chaque couche contient :

* une **matrice de poids** `W`
* un **vecteur de biais** `b`
* une **fonction dâ€™activation** `f`

Le rÃ©seau est dÃ©fini par la structure suivante :

```rust
pub struct NeuralNetwork {
    pub layers: Vec<Layer>,
    pub learning_rate: f64,
}
```

---

## âš™ï¸ Principe de fonctionnement

Lâ€™apprentissage dâ€™un rÃ©seau de neurones se dÃ©roule en **trois grandes Ã©tapes** :

### 1. ğŸ§® Propagation avant (Forward Propagation)

Les donnÃ©es dâ€™entrÃ©e passent de couche en couche :

[
Z^{(l)} = W^{(l)}A^{(l-1)} + b^{(l)}
]
[
A^{(l)} = f(Z^{(l)})
]

oÃ¹ :

* ( A^{(l)} ) = activations de la couche l
* ( W^{(l)} ) = poids
* ( b^{(l)} ) = biais
* ( f ) = fonction dâ€™activation (ReLU, Sigmoid, etc.)

---

### 2. ğŸ“‰ Calcul de la perte (Loss)

On mesure lâ€™Ã©cart entre la prÃ©diction et la vÃ©ritÃ© avec la **Mean Squared Error (MSE)** :

[
L = \frac{1}{m} \sum_{i=1}^{m} (y_{pred}^{(i)} - y_{true}^{(i)})^2
]

---

### 3. ğŸ” RÃ©tropropagation (Backpropagation)

Le cÅ“ur de lâ€™apprentissage : on calcule les **gradients** de la perte par rapport aux poids et biais, puis on les met Ã  jour.

#### Ã‰tape 1 â€“ Erreur de sortie

[
\delta^{(L)} = (A^{(L)} - Y) \odot f'(Z^{(L)})
]

#### Ã‰tape 2 â€“ Gradients

[
dW^{(l)} = \frac{1}{m} \delta^{(l)} (A^{(l-1)})^T
]
[
db^{(l)} = \frac{1}{m} \sum \delta^{(l)}
]

#### Ã‰tape 3 â€“ Propagation de lâ€™erreur

[
\delta^{(l-1)} = (W^{(l)})^T \delta^{(l)} \odot f'(Z^{(l-1)})
]

#### Ã‰tape 4 â€“ Mise Ã  jour des paramÃ¨tres

[
W^{(l)} := W^{(l)} - \eta \cdot dW^{(l)}
]
[
b^{(l)} := b^{(l)} - \eta \cdot db^{(l)}
]

oÃ¹ :

* ( \eta ) = learning rate
* ( \odot ) = produit Ã©lÃ©ment par Ã©lÃ©ment (Hadamard)

---

## ğŸ§  Structure du code

### 1. `Layer`

Chaque couche contient ses poids, biais et sa fonction dâ€™activation.

```rust
pub struct Layer {
    pub weights: Array2<f64>,
    pub biases: Array2<f64>,
    pub activation: Activation,
}
```

MÃ©thodes principales :

* `forward()` â†’ calcule ( Z ) et ( A )
* `update_parameters()` â†’ met Ã  jour les poids et biais :

  ```rust
  pub fn update_parameters(&mut self, dw: &Array2<f64>, db: &Array2<f64>, learning_rate: f64) {
      self.weights = &self.weights - learning_rate * dw;
      self.biases = &self.biases - learning_rate * db;
  }
  ```

---

### 2. `NeuralNetwork`

```rust
pub struct NeuralNetwork {
    pub layers: Vec<Layer>,
    pub learning_rate: f64,
}
```

MÃ©thodes :

* `new()` â†’ construit le rÃ©seau Ã  partir dâ€™une architecture donnÃ©e
* `forward()` â†’ passe avant complÃ¨te
* `train_epoch()` â†’ une Ã©poque dâ€™entraÃ®nement
* `train()` â†’ boucle dâ€™entraÃ®nement complÃ¨te
* `compute_loss()` â†’ calcule la perte MSE
* `evaluate()` â†’ mesure la prÃ©cision
* `predict()` â†’ fait une prÃ©diction

---

## ğŸ“˜ Exemple dâ€™utilisation

### Exemple : apprentissage du XOR ğŸ”€

```rust
use ndarray::array;
use neural_network::NeuralNetwork;
use neural_network::activation::Activation;

fn main() {
    let x_train = array![
        [0.0, 0.0, 1.0, 1.0],
        [0.0, 1.0, 0.0, 1.0]
    ];

    let y_train = array![
        [0.0, 1.0, 1.0, 0.0]
    ];

    let architecture = [
        (2, Activation::Relu),
        (3, Activation::Relu),
        (1, Activation::Sigmoid),
    ];

    let mut nn = NeuralNetwork::new(&architecture, 0.1);

    nn.print_architecture();

    let losses = nn.train(&x_train, &y_train, 10000);
    println!("Final loss: {:?}", losses.last());

    let predictions = nn.predict(&x_train);
    println!("Predictions:\n{:?}", predictions);
}
```

### Sortie attendue :

```
ğŸ§  Architecture du rÃ©seau:
  Couche 1: 2 neurones (Relu)
  Couche 2: 3 neurones (Relu)
  Couche 3: 1 neurone (Sigmoid)

ğŸš€ DÃ©but de l'entraÃ®nement...
Epoch 0 - Loss: 0.250000
Epoch 1000 - Loss: 0.040121
Epoch 5000 - Loss: 0.007231
Epoch 9999 - Loss: 0.002341
```

---

## ğŸ“Š RÃ©sultats attendus

Le modÃ¨le apprend la fonction XOR :

| EntrÃ©e | Sortie attendue | Sortie prÃ©dite |
| :----: | :-------------: | :------------: |
| [0, 0] |        0        |      ~0.01     |
| [0, 1] |        1        |      ~0.98     |
| [1, 0] |        1        |      ~0.97     |
| [1, 1] |        0        |      ~0.05     |

---

## ğŸ§® Fonctions dâ€™activation supportÃ©es

| Fonction    | Formule                         | DÃ©rivÃ©e                                          |
| ----------- | ------------------------------- | ------------------------------------------------ |
| **Sigmoid** | ( f(x) = \frac{1}{1 + e^{-x}} ) | ( f'(x) = f(x)(1 - f(x)) )                       |
| **ReLU**    | ( f(x) = \max(0, x) )           | ( f'(x) = 1 \text{ si } x > 0, 0 \text{ sinon} ) |
| **Tanh**    | ( f(x) = \tanh(x) )             | ( f'(x) = 1 - \tanh^2(x) )                       |

---

## ğŸ”§ AmÃ©liorations possibles

* [ ] Ajouter la rÃ©gularisation L2 / Dropout
* [ ] Ajouter la normalisation (BatchNorm)
* [ ] Support pour softmax + cross-entropy
* [ ] Sauvegarde / chargement des poids
* [ ] Visualisation des pertes avec `plotters`

---

## ğŸ“œ Licence

MIT License Â© 2025 â€“ CrÃ©Ã© par **Martial Wato**

---

Souhaites-tu que je te **gÃ©nÃ¨re directement le fichier `README.md` complet** (avec les formules rendues en Markdown mathÃ©matique, les titres stylÃ©s, et ton nom dâ€™auteur) que tu pourras **coller dans ton dÃ©pÃ´t GitHub** ?
Je peux le formater directement pour un rendu professionnel sur GitHub.
